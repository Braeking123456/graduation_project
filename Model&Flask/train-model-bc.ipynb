{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-11T16:01:36.816019Z","iopub.status.busy":"2024-06-11T16:01:36.815586Z","iopub.status.idle":"2024-06-11T16:01:36.825067Z","shell.execute_reply":"2024-06-11T16:01:36.823631Z","shell.execute_reply.started":"2024-06-11T16:01:36.815989Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","import os"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T16:01:36.828015Z","iopub.status.busy":"2024-06-11T16:01:36.827339Z","iopub.status.idle":"2024-06-11T16:01:36.851243Z","shell.execute_reply":"2024-06-11T16:01:36.849843Z","shell.execute_reply.started":"2024-06-11T16:01:36.827975Z"},"trusted":true},"outputs":[],"source":["# Define the path to the dataset directory\n","dataset_path = \"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT\"\n","\n","# Get the list of image files\n","image_files = []\n","labels = []\n","\n","# Iterate over the directories\n","for class_name in ['benign', 'malignant', 'normal']:\n","    class_path = os.path.join(dataset_path, class_name)\n","    for filename in os.listdir(class_path):\n","        image_path = os.path.join(class_path, filename)\n","        image_files.append(image_path)\n","        labels.append(class_name)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T16:01:36.853295Z","iopub.status.busy":"2024-06-11T16:01:36.852855Z","iopub.status.idle":"2024-06-11T16:01:36.893773Z","shell.execute_reply":"2024-06-11T16:01:36.892659Z","shell.execute_reply.started":"2024-06-11T16:01:36.853256Z"},"trusted":true},"outputs":[],"source":["# Convert labels to numerical values\n","from tensorflow.keras.utils import to_categorical\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(labels)\n","\n","# Convert labels to one-hot encoded format\n","labels = to_categorical(labels)\n","\n","# Split the data into train, validation, and test sets with 80/10/10\n","X_train_full, X_test, y_train_full, y_test = train_test_split(image_files, labels, test_size=0.2, random_state=42, stratify=labels)\n","X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1111, random_state=42, stratify=y_train_full)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T16:01:36.897252Z","iopub.status.busy":"2024-06-11T16:01:36.896307Z","iopub.status.idle":"2024-06-11T16:01:36.903612Z","shell.execute_reply":"2024-06-11T16:01:36.902399Z","shell.execute_reply.started":"2024-06-11T16:01:36.897217Z"},"trusted":true},"outputs":[],"source":["# Define a function to load and preprocess the images\n","def load_preprocess_image(image_path, target_size=(150, 150)):\n","    \"\"\"Loads and preprocesses an image.\"\"\"\n","    image = Image.open(image_path)\n","    image = image.resize(target_size)\n","    image = image.convert('RGB')  # Convert to RGB\n","    image = np.array(image)\n","    image = image / 255.0\n","    return image"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T16:01:36.905545Z","iopub.status.busy":"2024-06-11T16:01:36.905137Z","iopub.status.idle":"2024-06-11T16:02:04.926551Z","shell.execute_reply":"2024-06-11T16:02:04.925312Z","shell.execute_reply.started":"2024-06-11T16:01:36.905514Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train data shape: (1121, 150, 150, 3) (1121, 3)\n","Validation data shape: (141, 150, 150, 3) (141, 3)\n","Test data shape: (316, 150, 150, 3) (316, 3)\n"]}],"source":["\n","# Load and preprocess the training images and labels\n","X_train = [load_preprocess_image(image_path) for image_path in X_train]\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","\n","# Load and preprocess the validation images and labels\n","X_val = [load_preprocess_image(image_path) for image_path in X_val]\n","X_val = np.array(X_val)\n","y_val = np.array(y_val)\n","\n","# Load and preprocess the testing images and labels\n","X_test = [load_preprocess_image(image_path) for image_path in X_test]\n","X_test = np.array(X_test)\n","y_test = np.array(y_test)\n","\n","# Print the shapes of the resulting datasets\n","print(\"Train data shape:\", X_train.shape, y_train.shape)\n","print(\"Validation data shape:\", X_val.shape, y_val.shape)\n","print(\"Test data shape:\", X_test.shape, y_test.shape)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T16:02:04.928081Z","iopub.status.busy":"2024-06-11T16:02:04.927759Z","iopub.status.idle":"2024-06-11T16:02:05.230779Z","shell.execute_reply":"2024-06-11T16:02:05.229715Z","shell.execute_reply.started":"2024-06-11T16:02:04.928055Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}],"source":["\n","# Initialize the model\n","model = Sequential()\n","\n","# Add convolutional layers\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","\n","# Add more convolutional layers\n","model.add(Conv2D(256, (3, 3), activation='relu'))\n","model.add(MaxPooling2D((2, 2)))\n","\n","# Flatten the output\n","model.add(Flatten())\n","\n","# Add dense layers\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(3, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T16:21:01.194637Z","iopub.status.busy":"2024-06-11T16:21:01.193697Z","iopub.status.idle":"2024-06-11T16:28:57.568601Z","shell.execute_reply":"2024-06-11T16:28:57.567793Z","shell.execute_reply.started":"2024-06-11T16:21:01.194604Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 825ms/step - accuracy: 0.8583 - loss: 0.3467 - val_accuracy: 0.7305 - val_loss: 0.9495\n","Epoch 2/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 811ms/step - accuracy: 0.8704 - loss: 0.2981 - val_accuracy: 0.7092 - val_loss: 1.0108\n","Epoch 3/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 819ms/step - accuracy: 0.8639 - loss: 0.3207 - val_accuracy: 0.7730 - val_loss: 0.7788\n","Epoch 4/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 822ms/step - accuracy: 0.9094 - loss: 0.2330 - val_accuracy: 0.7801 - val_loss: 1.0019\n","Epoch 5/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 819ms/step - accuracy: 0.9397 - loss: 0.1524 - val_accuracy: 0.7589 - val_loss: 1.4014\n","Epoch 6/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 815ms/step - accuracy: 0.9474 - loss: 0.1441 - val_accuracy: 0.6312 - val_loss: 2.0328\n","Epoch 7/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 810ms/step - accuracy: 0.8044 - loss: 0.6879 - val_accuracy: 0.7163 - val_loss: 0.7526\n","Epoch 8/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 830ms/step - accuracy: 0.8900 - loss: 0.3092 - val_accuracy: 0.7234 - val_loss: 0.6787\n","Epoch 9/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 816ms/step - accuracy: 0.9547 - loss: 0.1300 - val_accuracy: 0.7872 - val_loss: 1.0674\n","Epoch 10/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 818ms/step - accuracy: 0.9769 - loss: 0.0737 - val_accuracy: 0.7376 - val_loss: 1.2148\n","Epoch 11/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 824ms/step - accuracy: 0.9772 - loss: 0.0892 - val_accuracy: 0.7518 - val_loss: 1.1339\n","Epoch 12/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 820ms/step - accuracy: 0.9877 - loss: 0.0507 - val_accuracy: 0.7589 - val_loss: 1.1471\n","Epoch 13/70\n","\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 817ms/step - accuracy: 0.9886 - loss: 0.0416 - val_accuracy: 0.7518 - val_loss: 1.5473\n","Training Accuracy: 0.989295244216919 Train loss: 0.09363178163766861\n","Testing Accuracy: 0.797468364238739 Test Loss: 0.5536373853683472\n"]}],"source":["# Train the model\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","model.fit(X_train, y_train, batch_size=32, epochs=70, validation_data=(X_val, y_val), callbacks=[early_stopping])\n","\n","# Evaluate the model on training and test data\n","train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n","test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n","\n","print('Training Accuracy:', train_accuracy, \"Train loss:\", train_loss)\n","\n"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T16:37:20.276940Z","iopub.status.busy":"2024-06-11T16:37:20.276127Z","iopub.status.idle":"2024-06-11T16:37:20.377117Z","shell.execute_reply":"2024-06-11T16:37:20.375990Z","shell.execute_reply.started":"2024-06-11T16:37:20.276896Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","Predicted Class: normal\n"]}],"source":["\n","\n","# Example: Predicting using an image\n","def predict_image(image_path):\n","    preprocessed_image = load_preprocess_image(image_path)\n","    preprocessed_image = np.expand_dims(preprocessed_image, axis=0)  # Add an extra dimension for batch size\n","    detect = model.predict(preprocessed_image)\n","    predicted_class_index = np.argmax(detect[0])\n","    classes = ['benign', 'malignant', 'normal']\n","    predicted_class = classes[predicted_class_index]\n","    return predicted_class\n","\n","# Example usage: Replace 'image_path' with the path to your image\n","image_path = '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/normal/normal (88).png'\n","predicted_class = predict_image(image_path)\n","print(\"Predicted Class:\", predicted_class)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-06-11T16:38:38.688676Z","iopub.status.busy":"2024-06-11T16:38:38.688170Z","iopub.status.idle":"2024-06-11T16:38:38.896016Z","shell.execute_reply":"2024-06-11T16:38:38.894813Z","shell.execute_reply.started":"2024-06-11T16:38:38.688636Z"},"trusted":true},"outputs":[],"source":["# Save the model\n","model.save('BreastCancer_TrainModel.h5')\n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1209633,"sourceId":2021025,"sourceType":"datasetVersion"}],"dockerImageVersionId":30732,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
